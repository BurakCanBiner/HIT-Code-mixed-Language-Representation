{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32814141",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Error: Cannot use NVML, as it failed to initialize\n",
      "│   exception = (ErrorException(\"could not load symbol \\\"nvmlInitWithFlags\\\":\\nThe specified procedure could not be found. \"), Union{Ptr{Nothing}, Base.InterpreterIP}[Ptr{Nothing} @0x00000000026948e5, Ptr{Nothing} @0x0000000002723c09, Ptr{Nothing} @0x00000000027241e7, Ptr{Nothing} @0x0000000002694324, Ptr{Nothing} @0x00000000143ecd24, Ptr{Nothing} @0x00000000143ed0e3, Ptr{Nothing} @0x00000000143e08ce, Ptr{Nothing} @0x00000000143e09f7, Ptr{Nothing} @0x000000000273f1e0, Ptr{Nothing} @0x00000000027357b0, Ptr{Nothing} @0x00000000143c78ac, Ptr{Nothing} @0x00000000143c8b46, Ptr{Nothing} @0x00000000143cad09, Ptr{Nothing} @0x00000000143ccde3, Ptr{Nothing} @0x00000000143cdac3, Ptr{Nothing} @0x000000000273ec66, Ptr{Nothing} @0x000000000274098c, Ptr{Nothing} @0x0000000002740561, Ptr{Nothing} @0x00000000027414af, Ptr{Nothing} @0x00000000143bc565, Ptr{Nothing} @0x00000000143bc93f, Ptr{Nothing} @0x00000000143b9528, Ptr{Nothing} @0x0000000002716186, Ptr{Nothing} @0x0000000014386192, Ptr{Nothing} @0x00000000143863c6, Ptr{Nothing} @0x00000000143863e3, Ptr{Nothing} @0x00000000027274e4])\n",
      "└ @ CUDA.NVML C:\\Users\\brkcn\\.julia\\packages\\CUDA\\YpW0k\\lib\\nvml\\NVML.jl:39\n"
     ]
    }
   ],
   "source": [
    "using Statistics\n",
    "using Metrics\n",
    "using Knet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "125beb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading data for sentiment classification\n",
    "# it's already divided into train/dev/test\n",
    "\n",
    "function read_sentiment_data(file_path)\n",
    "    labels = []\n",
    "    data = []\n",
    "    try\n",
    "        open(file_path) do f\n",
    "            while ! eof(f)      \n",
    "                s = readline(f) \n",
    "                s = lowercase.(s)\n",
    "                s = replace.(s, r\"[,.:;?!()]\" => \"\")\n",
    "                s_with_spaces = replace(s, '\\t' => ' ') \n",
    "                temp = split(s_with_spaces,\" \")\n",
    "                \n",
    "                push!(labels,temp[end-1])\n",
    "                push!(data,temp[2:end-2])\n",
    "            end\n",
    "        end\n",
    "    catch \n",
    "        println(\"file doesn't exist\")\n",
    "    end\n",
    "    return data, labels\n",
    "end\n",
    "\n",
    "path = \"test.txt\"\n",
    "#path = raw\"C:\\Users\\brkcn\\HIT-ACL2021-Codemixed-Representation\\data\\malayalam\\malayalam_train.tsv\"\n",
    "#path = raw\"C:\\Users\\brkcn\\HIT-ACL2021-Codemixed-Representation\\data\\tamil\\tamil_train.tsv\"\n",
    "#path = raw\"C:\\Users\\brkcn\\HIT-ACL2021-Codemixed-Representation\\data\\hindi_sentiment\\IIITH_Codemixed.txt\"\n",
    "sentiment_data, sentiment_labels = read_sentiment_data(path);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2a6f481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading data for machine translation\n",
    "# it's already divided into train/dev/test\n",
    "function read_mt_data(file_path)\n",
    "    data = []\n",
    "    try\n",
    "        open(file_path) do f\n",
    "            while ! eof(f)      \n",
    "                s = readline(f) \n",
    "                s = lowercase.(s)\n",
    "                s = replace.(s, r\"[,.:;?!()]\" => \"\")\n",
    "                s = replace(s, '\\t' => ' ') \n",
    "                s = split(s,\" \")\n",
    "                push!(data,s)\n",
    "            end\n",
    "        end\n",
    "    catch \n",
    "        println(\"file doesn't exist\")\n",
    "    end\n",
    "    data\n",
    "end\n",
    "\n",
    "path = raw\"C:\\Users\\brkcn\\HIT-ACL2021-Codemixed-Representation\\data\\IITPatna-CodeMixedMT\\train.src\"\n",
    "mt_data= read_mt_data(path);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "401ce070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading data for pos tagging\n",
    "function read_pos_tagging_data(file_path)\n",
    "    words = []\n",
    "    langs = []\n",
    "    tags = []\n",
    "    try\n",
    "        open(file_path) do f\n",
    "            while ! eof(f)\n",
    "                s = readline(f) \n",
    "                if length(s) != 0\n",
    "                    if s[1] != '@'\n",
    "                        s = replace(s, '\\t' => ' ') \n",
    "                        s = split(s,\" \")\n",
    "                        push!(words,s[1])\n",
    "                        push!(langs,s[2])\n",
    "                        push!(tags,s[3])\n",
    "                    end\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "    catch \n",
    "        println(\"error during reading pos tagging data\")\n",
    "    end\n",
    "    words, langs, tags\n",
    "end\n",
    "path = raw\"C:\\Users\\brkcn\\HIT-ACL2021-Codemixed-Representation\\data\\bengali_POS\\TWT_BN_EN_FN.txt\"\n",
    "pos_word, pos_langs, pos_tags = read_pos_tagging_data(path);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee8ae17d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vec_labels (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Randomly predcting for now\n",
    "function pred_sentiment(X)\n",
    "    preds = []\n",
    "    for sentence in X\n",
    "        push!(preds,rand(1:4))\n",
    "    end\n",
    "    preds\n",
    "end\n",
    "\n",
    "\n",
    "function vec_labels(y)\n",
    "    num_labels = []\n",
    "    for label in y\n",
    "        if label == \"positive\"\n",
    "            push!(num_labels,1)\n",
    "        elseif label == \"negative\"\n",
    "            push!(num_labels,2)\n",
    "        elseif label == \"mixed_feelings\"\n",
    "            push!(num_labels,3)\n",
    "        else\n",
    "            push!(num_labels,4)\n",
    "        end\n",
    "    end\n",
    "    num_labels\n",
    "end\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "44d0890d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment f1 score: 0.21899710633845815\n",
      "sentiment precision: 0.24714519576778163\n",
      "sentiment sentiment recall: 0.2553106750175261\n"
     ]
    }
   ],
   "source": [
    "function calculate_metrics(pred,y,num_classes)\n",
    "    y_len = length(y)\n",
    "    conf_mat = zeros(Int16,num_classes,num_classes)\n",
    "    for i in 1:y_len\n",
    "        conf_mat[pred[i],y[i]] += 1\n",
    "    end\n",
    "    positives = []\n",
    "    for j in 1:num_classes\n",
    "        push!(positives,conf_mat[j,j])\n",
    "    end\n",
    "    recall = positives./sum(conf_mat,dims=1)'\n",
    "    precision = positives./sum(conf_mat,dims=2)\n",
    "    f1_score =  2*(precision.*recall)./(precision.+recall)\n",
    "    mean(f1_score),mean(precision),mean(recall)\n",
    "end\n",
    "\n",
    "\n",
    "y = vec_labels(sentiment_labels)\n",
    "pred_y  = pred_sentiment(sentiment_data)\n",
    "sentiment_f1_score, sentiment_precision, sentiment_recall =  calculate_metrics(pred_y,y,4)\n",
    "\n",
    "\n",
    "\n",
    "println(\"sentiment f1 score: $sentiment_f1_score\")\n",
    "println(\"sentiment precision: $sentiment_precision\")\n",
    "println(\"sentiment sentiment recall: $sentiment_recall\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "497941b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bleu score: 0.7253666236200924\n",
      "rogue score dict:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedCollections.OrderedDict{String, Float64} with 9 entries:\n",
       "  \"rouge_1 / f_score\" => 0.75\n",
       "  \"rouge_1 / r_score\" => 0.75\n",
       "  \"rouge_1 / p_score\" => 0.75\n",
       "  \"rouge_2 / f_score\" => 0.333333\n",
       "  \"rouge_2 / r_score\" => 0.333333\n",
       "  \"rouge_2 / p_score\" => 0.333333\n",
       "  \"rouge_l / f_score\" => 0.75\n",
       "  \"rouge_l / r_score\" => 0.75\n",
       "  \"rouge_l / p_score\" => 0.75"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing bleu and rogue metrics for machine translation task later on.\n",
    "\n",
    "ref_corpus = [[\"Example of bleu score\"], [\"This is an apple\"]]\n",
    "translated_corpus = [\"Example to bleu score\", \"This no a apple\"]\n",
    "bleu_result = bleu_score(ref_corpus,translated_corpus)\n",
    "println(\"bleu score: $(bleu_result[1])\")\n",
    "\n",
    "hypothesis = [\"Example for bleu score\", \"This cz an apple\"]\n",
    "ref_corpus = [\"Example of bleu score\", \"This is an apple\"]\n",
    "println(\"rogue score dict:\")\n",
    "rouge_out = rouge(hypothesis, ref_corpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e3e0708c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13563×150 Matrix{Float64}:\n",
       " 0.305849   0.773973   0.422861   …  0.532339   0.527935   0.1201\n",
       " 0.590452   0.428254   0.886631      0.880701   0.53276    0.151884\n",
       " 0.109101   0.0890532  0.37157       0.273779   0.0362677  0.688134\n",
       " 0.878168   0.863311   0.279708      0.0534905  0.0217467  0.120134\n",
       " 0.752377   0.405445   0.104159      0.179468   0.420645   0.0227377\n",
       " 0.134298   0.155499   0.129335   …  0.524802   0.918577   0.727608\n",
       " 0.359881   0.689466   0.563064      0.0850109  0.919817   0.361457\n",
       " 0.132755   0.367557   0.0818739     0.487579   0.738634   0.742328\n",
       " 0.613248   0.25118    0.156225      0.0865275  0.743104   0.298876\n",
       " 0.547914   0.611622   0.291513      0.298254   0.981845   0.941216\n",
       " 0.0663833  0.426276   0.513892   …  0.565518   0.72773    0.281176\n",
       " 0.953749   0.864944   0.961623      0.858811   0.96747    0.938396\n",
       " 0.0443058  0.649013   0.165217      0.6621     0.797268   0.397158\n",
       " ⋮                                ⋱                        \n",
       " 0.485291   0.519219   0.0356809     0.141311   0.924927   0.828888\n",
       " 0.231502   0.822929   0.543789      0.173183   0.795358   0.221586\n",
       " 0.70179    0.472026   0.605711      0.340812   0.508136   0.252791\n",
       " 0.416278   0.80228    0.632921      0.473111   0.254769   0.91981\n",
       " 0.943784   0.80445    0.932964   …  0.710349   0.257043   0.935021\n",
       " 0.377631   0.995168   0.0958236     0.995971   0.0283184  0.847035\n",
       " 0.273456   0.495856   0.311664      0.807616   0.63609    0.800476\n",
       " 0.660449   0.261931   0.412818      0.0296249  0.523768   0.00480214\n",
       " 0.89813    0.249927   0.0807587     0.156885   0.569436   0.335942\n",
       " 0.971748   0.925246   0.965309   …  0.70781    0.886275   0.408753\n",
       " 0.915192   0.724116   0.352573      0.329319   0.135221   0.00515989\n",
       " 0.910254   0.688447   0.795073      0.459335   0.309066   0.280712"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#generating word embeddings \n",
    "\n",
    "path = raw\"C:\\Users\\brkcn\\HIT-ACL2021-Codemixed-Representation\\data\\malayalam\\malayalam_train.tsv\"\n",
    "sentiment_data, sentiment_labels = read_sentiment_data(path);\n",
    "\n",
    "function generate_word_embeddings(sentiment_data,embedding_space=150)\n",
    "    word_counts = Dict()\n",
    "\n",
    "    for sentence in sentiment_data\n",
    "        for word in sentence\n",
    "           word_counts[word] = get(word_counts, word, 0) + 1\n",
    "        end\n",
    "    end\n",
    "\n",
    "    sorted_word_counts = sort(collect(word_counts), by=x->x[2],rev=true)\n",
    "\n",
    "    word_symbols = Dict([(\"<unk>\", 1), (\"<s>\", 2),(\"<pad>\",3)])\n",
    "    for (index,word_n_count ) in enumerate(sorted_word_counts)\n",
    "        word_symbols[word_n_count[1]] = index + 3\n",
    "    end\n",
    "    embedding_count = length(word_symbols)\n",
    "    word_embeddings =  rand(embedding_count,embedding_space)\n",
    "    \n",
    "    sorted_word_counts, word_embeddings, word_symbols\n",
    "end\n",
    "\n",
    "sorted_word_counts, word_embeddings, word_symbols = generate_word_embeddings(sentiment_data)\n",
    "word_embeddings\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4d297210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4852-element Vector{Any}:\n",
       " AbstractString[\"<pad>\", \"<pad>\", \"<pad>\", \"<pad>\", \"<pad>\", \"<pad>\", \"<pad>\", \"<pad>\", \"<pad>\", \"<pad>\", \"<pad>\", \"<pad>\"]\n",
       " AbstractString[\"hoo\", \"mammokka\", \"police\", \"vesham\", \"aaha\", \"anthas\", \"<pad>\", \"<pad>\", \"<pad>\", \"<pad>\", \"<pad>\", \"<pad>\"]\n",
       " AbstractString[\"oru\", \"rekshayum\", \"illakidilam\", \"kannu\", \"nananjupoyi\", \"<pad>\", \"<pad>\", \"<pad>\", \"<pad>\", \"<pad>\", \"<pad>\", \"<pad>\"]\n",
       " AbstractString[\"ikka\", \"\", \"\", \"\", \"\", \"waiting\", \"<pad>\", \"<pad>\", \"<pad>\", \"<pad>\", \"<pad>\", \"<pad>\"]\n",
       " AbstractString[\"raju\", \"ettante\", \"oro\", \"shorttum\", \"ijathi\", \"ppwli\", \"<pad>\", \"<pad>\", \"<pad>\", \"<pad>\", \"<pad>\", \"<pad>\"]\n",
       " AbstractString[\"ettan\", \"fansil\", \"netti\", \"poya\", \"aarenkilum\", \"undo\", \"\", \"\", \"\", \"#maduraraja#waiting\", \"#\", \"<pad>\"]\n",
       " AbstractString[\"waiting\", \"to\", \"see\", \"mammukaas\", \"undaa\", \"🤣\", \"<pad>\", \"<pad>\", \"<pad>\", \"<pad>\", \"<pad>\", \"<pad>\"]\n",
       " SubString{String}[\"last\", \"aa\", \"chadi\", \"adi\", \"uff\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"]\n",
       " AbstractString[\"1\", \"day\", \"achu\", \"5\", \"million\", \"views\", \"kooda\", \"varla\", \"<pad>\", \"<pad>\", \"<pad>\", \"<pad>\"]\n",
       " AbstractString[\"heavy\", \"mass\", \"<pad>\", \"<pad>\", \"<pad>\", \"<pad>\", \"<pad>\", \"<pad>\", \"<pad>\", \"<pad>\", \"<pad>\", \"<pad>\"]\n",
       " AbstractString[\"i\", \"a\", \"m\", \"a\", \"katta\", \"mammookka\", \"fan\", \"<pad>\", \"<pad>\", \"<pad>\", \"<pad>\", \"<pad>\"]\n",
       " AbstractString[\"pulimurgan\", \"2\", \"adyam\", \"oralde\", \"thallu\", \"pinne\", \"same\", \"kattil\", \"ottakkulla\", \"adi\", \"<pad>\", \"<pad>\"]\n",
       " AbstractString[\"nte\", \"ponno\", \"oru\", \"raksha\", \"illa\", \"ennaaa\", \"trailer\", \"<pad>\", \"<pad>\", \"<pad>\", \"<pad>\", \"<pad>\"]\n",
       " ⋮\n",
       " AbstractString[\"trillernu\", \"vandi\", \"wait\", \"cheydhadh\", \"njan\", \"maathramaanno\", \"<pad>\", \"<pad>\", \"<pad>\", \"<pad>\", \"<pad>\", \"<pad>\"]\n",
       " AbstractString[\"mammooka\", \"pwoli\", \"\", \"mamanga\", \"ulsavam\", \"aayirikkum\", \"nov\", \"21nu\", \"\", \"katta\", \"waiting\", \"<pad>\"]\n",
       " SubString{String}[\"padam\", \"kandathinte\", \"shesham\", \"trailer\", \"kannunna\", \"ethra\", \"perude\", \"onne\", \"\", \"\", \"\", \"like\"]\n",
       " AbstractString[\"ettan\", \"ee\", \"onam\", \"angu\", \"eduthu\", \"makkale‼‼\", \"<pad>\", \"<pad>\", \"<pad>\", \"<pad>\", \"<pad>\", \"<pad>\"]\n",
       " AbstractString[\"soubin\", \"fans\", \"like\", \"adi\", \"makkale\", \"<pad>\", \"<pad>\", \"<pad>\", \"<pad>\", \"<pad>\", \"<pad>\", \"<pad>\"]\n",
       " AbstractString[\"ufff\", \"poli\", \"\", \"chekkan\", \"kidukki\", \"\", \"hbd\", \"ikka\", \"<pad>\", \"<pad>\", \"<pad>\", \"<pad>\"]\n",
       " AbstractString[\"varav\", \"kandit\", \"padam\", \"8\", \"nilayil\", \"pottunna\", \"thonnane\", \"<pad>\", \"<pad>\", \"<pad>\", \"<pad>\", \"<pad>\"]\n",
       " AbstractString[\"madhuraraja\", \"trailer\", \"kand\", \"ivide\", \"vannanvar\", \"likkeee\", \"<pad>\", \"<pad>\", \"<pad>\", \"<pad>\", \"<pad>\", \"<pad>\"]\n",
       " SubString{String}[\"njn\", \"pru\", \"lalettan\", \"fan\", \"ahn\", \"\", \"eee\", \"trailer\", \"mass\", \"ahn\", \"\", \"padam\"]\n",
       " AbstractString[\"valiya\", \"pratheesha\", \"illa\", \"nalla\", \"entertainment\", \"\", \"aayirikkum\", \"<pad>\", \"<pad>\", \"<pad>\", \"<pad>\", \"<pad>\"]\n",
       " AbstractString[\"dislike\", \"adikkunna\", \"kazhuthakalude\", \"mukhath\", \"adikkunnavar\", \"like\", \"<pad>\", \"<pad>\", \"<pad>\", \"<pad>\", \"<pad>\", \"<pad>\"]\n",
       " SubString{String}[\"adipoli\", \"pakshe\", \"oru\", \"sankadam\", \"ithinte\", \"thirakatha\", \"undakkan\", \"vendi\", \"12\", \"varshakalam\", \"parishramicha\", \"vyakthik\"]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adding pad token to have fixed length input.\n",
    "\n",
    "path = raw\"C:\\Users\\brkcn\\HIT-ACL2021-Codemixed-Representation\\data\\malayalam\\malayalam_train.tsv\"\n",
    "#path = \"test.txt\"\n",
    "sentiment_data, sentiment_labels = read_sentiment_data(path);\n",
    "\n",
    "function pad_data(sentiment_data,max_len = 15)\n",
    "    padded_sentiment_data = []\n",
    "    for sentence in sentiment_data\n",
    "        new_sentence = sentence\n",
    "        if length(sentence) > max_len\n",
    "            new_sentence = sentence[1:max_len]\n",
    "        elseif length(sentence) < max_len\n",
    "            pad_tokens =  repeat([\"<pad>\"], max_len - length(sentence))\n",
    "            new_sentence = vcat(sentence,pad_tokens)\n",
    "        end  \n",
    "        push!(padded_sentiment_data,new_sentence)\n",
    "    end\n",
    "    padded_sentiment_data\n",
    "end\n",
    "\n",
    "pad_data(sentiment_data,12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bed7395",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.3",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
